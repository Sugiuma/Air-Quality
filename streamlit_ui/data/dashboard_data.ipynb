{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0530b3-114b-43fa-bccf-27bee7374e0c",
   "metadata": {},
   "source": [
    "**Get city wise pollutants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18cdb426-380a-421a-a46f-8d6f7b56be27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       City         level_1   pollutants  avg_aqi_2022_2025  Good  Moderate  \\\n",
      "0  Agartala  top1_pollutant  PM2.5 (583)         126.697585   220       249   \n",
      "1  Agartala  top2_pollutant   PM10 (457)         126.697585   220       249   \n",
      "2  Agartala  top3_pollutant      O3 (64)         126.697585   220       249   \n",
      "3  Agartala  top4_pollutant     SO2 (52)         126.697585   220       249   \n",
      "4  Agartala  top5_pollutant       CO (2)         126.697585   220       249   \n",
      "5      Agra  top1_pollutant   PM10 (953)          84.232889   248       330   \n",
      "6      Agra  top2_pollutant  PM2.5 (522)          84.232889   248       330   \n",
      "7      Agra  top3_pollutant     O3 (180)          84.232889   248       330   \n",
      "8      Agra  top4_pollutant    NO2 (105)          84.232889   248       330   \n",
      "9      Agra  top5_pollutant     SO2 (64)          84.232889   248       330   \n",
      "\n",
      "   Poor  Satisfactory  Severe  Very Poor  \n",
      "0   215           318       0         33  \n",
      "1   215           318       0         33  \n",
      "2   215           318       0         33  \n",
      "3   215           318       0         33  \n",
      "4   215           318       0         33  \n",
      "5    12           535       0          0  \n",
      "6    12           535       0          0  \n",
      "7    12           535       0          0  \n",
      "8    12           535       0          0  \n",
      "9    12           535       0          0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sugan\\AppData\\Local\\Temp\\ipykernel_13004\\535918983.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(get_top_pollutants)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and parse data\n",
    "file_path = \"../../data/aqi.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Parse dates safely\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "\n",
    "# Filter for date range (2022â€“2025)\n",
    "df = df[(df[\"date\"] >= \"2022-01-01\") & (df[\"date\"] <= \"2025-05-31\")].copy()\n",
    "\n",
    "# Step 1: Compute average AQI per city (area)\n",
    "avg_aqi = (\n",
    "    df.groupby(\"area\")[\"aqi_value\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"aqi_value\": \"avg_aqi_2022_2025\"})\n",
    ")\n",
    "\n",
    "# Step 2: Clean and explode prominent pollutants\n",
    "pollutant_df = df[[\"area\", \"prominent_pollutants\"]].dropna().copy()\n",
    "pollutant_df[\"prominent_pollutants\"] = pollutant_df[\"prominent_pollutants\"].str.replace(\" \", \"\")\n",
    "pollutant_df = pollutant_df.assign(prominent_pollutants=pollutant_df[\"prominent_pollutants\"].str.split(','))\n",
    "pollutant_exploded = pollutant_df.explode(\"prominent_pollutants\")\n",
    "\n",
    "# Step 3: Count each pollutant per area\n",
    "pollutant_counts = (\n",
    "    pollutant_exploded\n",
    "    .groupby([\"area\", \"prominent_pollutants\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# Step 4: Get top 5 pollutants with counts for each city\n",
    "def get_top_pollutants(df_sub):\n",
    "    df_sorted = df_sub.sort_values(\"count\", ascending=False).head(5)\n",
    "    return pd.Series({\n",
    "        f\"top{i+1}_pollutant\": f\"{row.prominent_pollutants} ({row.count})\"\n",
    "        for i, row in enumerate(df_sorted.itertuples(index=False))\n",
    "    })\n",
    "\n",
    "top5_pollutants = (\n",
    "    pollutant_counts\n",
    "    .groupby(\"area\")\n",
    "    .apply(get_top_pollutants)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 5: Merge with average AQI\n",
    "final = top5_pollutants.merge(avg_aqi, on=\"area\", how=\"left\")\n",
    "\n",
    "# Rename for clarity\n",
    "final = final.rename(columns={\"area\": \"City\"})\n",
    "final = final.rename(columns={0: \"pollutants\"})  # if 0 exists\n",
    "\n",
    "# Step 6: Count occurrences of each air_quality_status per area\n",
    "status_counts = (\n",
    "    df.groupby(['area', 'air_quality_status'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # Converts rows to columns per status\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Optional: Rename columns for clarity\n",
    "status_counts.columns.name = None # remove group name\n",
    "status_counts = status_counts.rename(columns={\"area\": \"City\"})\n",
    "\n",
    "\n",
    "# Merge air quality status counts with final output\n",
    "final = final.merge(status_counts, on=\"City\", how=\"left\")\n",
    "\n",
    "# Output\n",
    "final.to_csv(\"city_pollutants_aqi_summary.csv\", index=False)\n",
    "print(final.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c7873-96b2-4dbf-ad30-0d860ad5e859",
   "metadata": {},
   "source": [
    "**Get citywise monthly average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a5619b-be1f-41b4-b181-6f24ab394f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse data\n",
    "file_path = \"../../data/aqi.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], dayfirst=True, errors=\"coerce\")\n",
    "df[\"month\"] = df[\"date\"].dt.to_period(\"M\")\n",
    "\n",
    "monthly_avg = (\n",
    "    df.groupby([\"area\", \"month\",\"state\"])[\"aqi_value\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "monthly_avg[\"month\"] = monthly_avg[\"month\"].astype(str)\n",
    "monthly_avg.to_csv(\"all_citywise_trend.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ce928-ac84-439d-966c-693aa9d844ef",
   "metadata": {},
   "source": [
    "**Merge Population and per capita income for Tier1 and Tier2 cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f5205c-0d30-4060-9f01-a6cf671afc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City         level_1   pollutants  avg_aqi_2022_2025  Good  Moderate  \\\n",
      "0  Ahmedabad  top1_pollutant  PM2.5 (708)         113.598573    26       632   \n",
      "1  Ahmedabad  top2_pollutant   PM10 (675)         113.598573    26       632   \n",
      "2  Ahmedabad  top3_pollutant    NO2 (138)         113.598573    26       632   \n",
      "3  Ahmedabad  top4_pollutant     O3 (130)         113.598573    26       632   \n",
      "4  Ahmedabad  top5_pollutant      CO (95)         113.598573    26       632   \n",
      "5  Bengaluru  top1_pollutant  PM10 (1035)          74.885333   169       143   \n",
      "6  Bengaluru  top2_pollutant  PM2.5 (490)          74.885333   169       143   \n",
      "7  Bengaluru  top3_pollutant     CO (338)          74.885333   169       143   \n",
      "8  Bengaluru  top4_pollutant     O3 (156)          74.885333   169       143   \n",
      "9  Bengaluru  top5_pollutant     NO2 (55)          74.885333   169       143   \n",
      "\n",
      "   Poor  Satisfactory  Severe  Very Poor  population  per_capita_income  \\\n",
      "0    33           430       0          0     9061819             389000   \n",
      "1    33           430       0          0     9061819             389000   \n",
      "2    33           430       0          0     9061819             389000   \n",
      "3    33           430       0          0     9061819             389000   \n",
      "4    33           430       0          0     9061819             389000   \n",
      "5     0           813       0          0    14395443             760000   \n",
      "6     0           813       0          0    14395443             760000   \n",
      "7     0           813       0          0    14395443             760000   \n",
      "8     0           813       0          0    14395443             760000   \n",
      "9     0           813       0          0    14395443             760000   \n",
      "\n",
      "  category            0  \n",
      "0   Tier 1  PM2.5 (708)  \n",
      "1   Tier 1   PM10 (675)  \n",
      "2   Tier 1    NO2 (138)  \n",
      "3   Tier 1     O3 (130)  \n",
      "4   Tier 1      CO (95)  \n",
      "5   Tier 1  PM10 (1035)  \n",
      "6   Tier 1  PM2.5 (490)  \n",
      "7   Tier 1     CO (338)  \n",
      "8   Tier 1     O3 (156)  \n",
      "9   Tier 1     NO2 (55)  \n"
     ]
    }
   ],
   "source": [
    "# Load AQI data (must have: City, aqi_value)\n",
    "df_aqi = pd.read_csv(\"city_pollutants_aqi_summary.csv\")  # Make sure it has a column like: City, aqi_value\n",
    "\n",
    "# Load income/population data (must have: City, population, per_capita_income)\n",
    "df_income = pd.read_csv(\"income.csv\")  # Columns: City, population, per_capita_income\n",
    "\n",
    "# Standardize city names (remove leading/trailing spaces, lowercase for consistency)\n",
    "for df in [df_aqi, df_income]:\n",
    "    df['City'] = df['City'].str.strip().str.lower()\n",
    "\n",
    "# Merge in steps\n",
    "merged = df_aqi.merge(df_income, on='City', how='inner')\n",
    "#merged = merged.merge(df_income, on='City', how='left')\n",
    "\n",
    "# Capitalize city names for readability\n",
    "merged['City'] = merged['City'].str.title()\n",
    "merged['0'] = merged['pollutants']\n",
    "# Save merged output (optional)\n",
    "merged.to_csv(\"merged_city_data.csv\", index=False)\n",
    "\n",
    "# Preview merged result\n",
    "print(merged.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3dd324-34d0-4b75-abeb-b166e664c346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  City  Composite_Score\n",
      "0                Delhi             0.91\n",
      "1               Mumbai             0.45\n",
      "16           Ghaziabad             0.43\n",
      "10               Patna             0.43\n",
      "2            Bengaluru             0.39\n",
      "22          Chandigarh             0.38\n",
      "15              Meerut             0.36\n",
      "5            Ahmedabad             0.35\n",
      "7              Kolkata             0.30\n",
      "6                 Pune             0.30\n",
      "9               Jaipur             0.30\n",
      "8                Surat             0.29\n",
      "4            Hyderabad             0.29\n",
      "11             Lucknow             0.29\n",
      "26              Nagpur             0.26\n",
      "23              Bhopal             0.24\n",
      "13       Visakhapatnam             0.23\n",
      "20               Kochi             0.23\n",
      "25              Kanpur             0.21\n",
      "3              Chennai             0.19\n",
      "24              Indore             0.18\n",
      "14              Nashik             0.13\n",
      "12          Coimbatore             0.09\n",
      "21            Varanasi             0.05\n",
      "19     Tiruchirappalli             0.04\n",
      "18  Thiruvananthapuram             0.03\n",
      "17             Madurai             0.02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load your two datasets\n",
    "df_aqi = pd.read_csv(\"merged_city_data.csv\")      # includes AQI + population + income\n",
    "df_city = pd.read_csv(\"income.csv\")           # only includes population, income\n",
    "\n",
    "# Step 2: Clean and standardize city names for merge\n",
    "df_aqi[\"City\"] = df_aqi[\"City\"].str.strip().str.title()\n",
    "df_city[\"City\"] = df_city[\"City\"].str.strip().str.title()\n",
    "# Clean population and income\n",
    "#df_city[\"population\"] = df_city[\"population\"].str.replace(\",\", \"\").astype(int)\n",
    "#df_city[\"per_capita_income\"] = df_city[\"per_capita_income\"].str.replace(\",\", \"\").astype(int)\n",
    "\n",
    "# Cap PCI at 300,000 INR\n",
    "df_city[\"per_capita_income_clean\"] = df_city[\"per_capita_income\"]\n",
    "\n",
    "# Step 1: Group AQI per city\n",
    "df_aqi_clean = df_aqi.groupby(\"City\", as_index=False)[\"avg_aqi_2022_2025\"].mean()\n",
    "\n",
    "# ðŸ”´ Optional: Make sure city metadata has one row per city\n",
    "# If df_city has duplicate city entries, this will remove them\n",
    "df_city_dedup = df_city.drop_duplicates(subset=\"City\")\n",
    "\n",
    "# Step 2: Merge\n",
    "df_merged = pd.merge(df_city_dedup, df_aqi_clean, on=\"City\", how=\"left\")\n",
    "\n",
    "# âœ… New line â€” create scored_df AFTER merge\n",
    "scored_df = df_merged.copy()\n",
    "\n",
    "# Step 5: Check for missing values after merge (optional)\n",
    "missing_aqi = scored_df[scored_df[\"avg_aqi_2022_2025\"].isna()]\n",
    "if not missing_aqi.empty:\n",
    "    print(\"Warning: AQI missing for the following cities:\")\n",
    "    print(missing_aqi[\"City\"].unique())\n",
    "\n",
    "# Step 6: Clean numeric columns\n",
    "for col in [\"population\", \"per_capita_income_clean\"]:\n",
    "    scored_df[col] = (\n",
    "        scored_df[col]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \"\")\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "scored_df[\"avg_aqi_2022_2025\"] = pd.to_numeric(scored_df[\"avg_aqi_2022_2025\"], errors=\"coerce\")\n",
    "\n",
    "# Drop missing AQI rows\n",
    "scored_df.dropna(subset=[\"avg_aqi_2022_2025\"], inplace=True)\n",
    "\n",
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scored_df[[\"Population_Score\", \"Income_Score\", \"AQI_Score\"]] = scaler.fit_transform(\n",
    "    scored_df[[\"population\", \"per_capita_income_clean\", \"avg_aqi_2022_2025\"]]\n",
    ")\n",
    "\n",
    "# Composite score\n",
    "scored_df[\"Composite_Score\"] = (\n",
    "  0.3 *  scored_df[\"Population_Score\"] +\n",
    "  0.2 * scored_df[\"Income_Score\"] +\n",
    "  0.5 *  scored_df[\"AQI_Score\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Sort and save\n",
    "top_cities = scored_df.sort_values(\"Composite_Score\", ascending=False)\n",
    "top_cities.to_csv(\"scored_city_market_ranking.csv\", index=False)\n",
    "print(top_cities[[\"City\", \"Composite_Score\"]].round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0dc6b79-ee4f-4a79-a461-0d7a95e79bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      City AQI_Rank* Population (2025 est.) PCI (â‚¹ lakh)  Composite_Score\n",
      "     Delhi Very High                  34.7M         4.61         0.908824\n",
      "    Mumbai      High                  22.1M         4.13         0.451488\n",
      " Ghaziabad      High                   1.2M         1.35         0.432555\n",
      "     Patna      High                   2.7M          1.2         0.431216\n",
      " Bengaluru  Moderate                  14.4M          7.6         0.386382\n",
      "Chandigarh      High                   1.3M          4.0         0.377751\n",
      "    Meerut      High                   1.9M          1.3         0.356111\n",
      " Ahmedabad      High                   9.1M         3.89         0.352562\n",
      "   Kolkata      High                  15.8M         1.54         0.303717\n",
      "      Pune      High                   7.5M         2.78         0.299606\n"
     ]
    }
   ],
   "source": [
    "# Create formatted columns\n",
    "top_cities[\"Population (2025 est.)\"] = (top_cities[\"population\"] / 1e6).round(1).astype(str) + \"M\"\n",
    "top_cities[\"PCI (â‚¹ lakh)\"] = (top_cities[\"per_capita_income_clean\"] / 1e5).round(2).astype(str)  # â‚¹1 lakh = 100,000\n",
    "top_cities[\"Composite Score\"] = top_cities[\"Composite_Score\"].round(2)\n",
    "\n",
    "# AQI Rank logic\n",
    "def classify_aqi_rank(aqi):\n",
    "    if aqi >= 200:\n",
    "        return \"Very High\"\n",
    "    elif aqi >= 100:\n",
    "        return \"High\"\n",
    "    elif aqi >= 50:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "top_cities[\"AQI_Rank*\"] = top_cities[\"avg_aqi_2022_2025\"].apply(classify_aqi_rank)\n",
    "\n",
    "# Display formatted table\n",
    "formatted = top_cities[[\"City\", \"AQI_Rank*\", \"Population (2025 est.)\", \"PCI (â‚¹ lakh)\", \"Composite_Score\"]]\n",
    "formatted.to_csv(\"composite_score.csv\")\n",
    "print(formatted.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cd402-723e-4dd7-94df-4d92a50c8167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
